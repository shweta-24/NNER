{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91170fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from CreateVectors import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efb67a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "\n",
    "data_file = \"GENIA_term_3.02/GENIAcorpus3.02.xml\"\n",
    "\n",
    "with open(data_file, 'r') as in_file:\n",
    "    contents = in_file.read()\n",
    "\n",
    "\n",
    "soup = BeautifulSoup(contents,\"xml\")\n",
    "\n",
    "articles = soup.find_all(\"article\")\n",
    "\n",
    "training_data = articles[:1600]\n",
    "testing_data = articles[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff75709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save array to text file\n",
    "def write_text_to_file(array, file):\n",
    "    with open(file, \"w\") as out_file:\n",
    "        for row in array:\n",
    "            out_file.write(str(row))\n",
    "            out_file.write('\\n')\n",
    "#write_text_to_file(sentences_text, output_text_file) #Uncomment if the a new text file should be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bb38743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all sentences from data (first return is sentences with tags, second return cleaned sentences)\n",
    "def get_sentences(data):\n",
    "    sentences = []\n",
    "    sentences_text = [] # The cleaned text without tags\n",
    "    for article in data:\n",
    "        sentences_in_article = article.find_all(\"sentence\")\n",
    "        for sentence in sentences_in_article:\n",
    "            sentences.append(sentence)\n",
    "            sentence_text = sentence.get_text()\n",
    "            sentence_text = re.sub('[\\.\\,\\(\\)]', '', sentence_text)\n",
    "            sentences_text.append(sentence_text)\n",
    "    return sentences, sentences_text\n",
    "\n",
    "_, training_text = get_sentences(training_data)\n",
    "_, testing_text = get_sentences(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e37f1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates list with all named entities from each sentence\n",
    "def get_entity_names(sentences):\n",
    "    names = []\n",
    "    for sentence in sentences:\n",
    "        cons = sentence.find_all(\"cons\")\n",
    "        sentence_cons = []\n",
    "        for con in cons:\n",
    "            sentence_cons.append(con.get_text())\n",
    "        names.append(sentence_cons)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9371d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns vectors to use for training ML-models\n",
    "# @param ngram - decides how many words to use for each input (each \"name\")\n",
    "# @return two vectors X and Y\n",
    "# X - a vector with each word (or ngram) from the corpus\n",
    "# Y - a corresponding vector with a 1 if the word is a named entity, 0 if it's not\n",
    "def get_name_vectors(sentences, names, ngram):\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    assert len(sentences) == len(names)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(sentences)):\n",
    "        text = sentences[i].split()\n",
    "                \n",
    "        for j in range(len(text)-ngram+1):\n",
    "            \n",
    "            sub = ' '.join(text[j:j+ngram])\n",
    "            \n",
    "            X.append(sub)\n",
    "            \n",
    "            if sub in names[i]:\n",
    "                Y.append(1)\n",
    "            else:\n",
    "                Y.append(0)\n",
    "                \n",
    "    return X,Y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee64ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to get X and Y vectors both training and testing data\n",
    "# (X vectors are only the n-grams in text, not word embeddings)\n",
    "\n",
    "training_sentences_raw, training_sentences = get_sentences(training_data)\n",
    "testing_sentences_raw, testing_sentences = get_sentences(testing_data)\n",
    "\n",
    "training_names = get_entity_names(training_sentences_raw)\n",
    "testing_names = get_entity_names(testing_sentences_raw)\n",
    "\n",
    "\n",
    "trainX1, trainY1 = get_name_vectors(training_sentences, training_names, 1)\n",
    "trainX2, trainY2 = get_name_vectors(training_sentences, training_names, 2)\n",
    "trainX3, trainY3 = get_name_vectors(training_sentences, training_names, 3)\n",
    "\n",
    "testX1, testY1 = get_name_vectors(testing_sentences, testing_names, 1)\n",
    "testX2, testY2 = get_name_vectors(testing_sentences, testing_names, 2)\n",
    "testX3, testY3 = get_name_vectors(testing_sentences, testing_names, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb44e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to create feature vectors and write them to file\n",
    "\n",
    "vic = Vectors()\n",
    "vic.create_vectors(training_text,3)\n",
    "vic.write_vectors_to_file(\"data/X_feature_vectors_v2/training_X3_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ddc3f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cell to write training and testing data to file\n",
    "\n",
    "write_text_to_file(trainX1, \"data/training_X1_no_punctuation\")\n",
    "write_text_to_file(trainX2, \"data/training_X2_no_punctuation\")\n",
    "write_text_to_file(trainX3, \"data/training_X3_no_punctuation\")\n",
    "\n",
    "write_text_to_file(trainY1, \"data/training_Y1_no_punctuation\")\n",
    "write_text_to_file(trainY2, \"data/training_Y2_no_punctuation\")\n",
    "write_text_to_file(trainY3, \"data/training_Y3_no_punctuation\")\n",
    "\n",
    "\n",
    "\n",
    "write_text_to_file(testX1, \"data/testing_X1_no_punctuation\")\n",
    "write_text_to_file(testX2, \"data/testing_X2_no_punctuation\")\n",
    "write_text_to_file(testX3, \"data/testing_X3_no_punctuation\")\n",
    "\n",
    "write_text_to_file(testY1, \"data/testing_Y1_no_punctuation\")\n",
    "write_text_to_file(testY2, \"data/testing_Y2_no_punctuation\")\n",
    "write_text_to_file(testY3, \"data/testing_Y3_no_punctuation\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
